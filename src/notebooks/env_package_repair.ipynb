{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests as requests\n",
    "import sqlite3\n",
    "import string\n",
    "import urllib\n",
    "import yaml\n",
    "\n",
    "import scoped_mapping\n",
    "\n",
    "from datetime import datetime\n",
    "from pkg_resources import get_distribution, DistributionNotFound\n",
    "from strsimpy.cosine import Cosine\n",
    "from xml.etree import ElementTree\n",
    "from tdda import rexpy\n",
    "\n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-provided data\n",
    "See repo README for notes on setting up SQLite databases of OBO ontologies with semantic-sql, relation-graph and rdftab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://www.ncbi.nlm.nih.gov/biosample/docs/packages/?format=xml\n",
    "# see also https://www.ncbi.nlm.nih.gov/biosample/docs/packages/\n",
    "biosample_packages_file = \"../../target/biosample_packages.xml\"\n",
    "\n",
    "# from ftp://ftp.ncbi.nlm.nih.gov//biosample/biosample_set.xml.gz\n",
    "# via harmonized_table.db.gz\n",
    "# in https://drive.google.com/drive/u/0/folders/1eL0v0stoduahjDpoDJIk3z2pJBAU4b2Y\n",
    "biosample_sqlite_file = \"../../target/harmonized-table.db\"\n",
    "\n",
    "# where do we require a single ontology and where can we use multiple?\n",
    "target_onto_prefix = \"ENVO\"\n",
    "# PO\n",
    "\n",
    "first_pass_ontologies = [\"envo\", \"ncbitaxon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It's nice to see everything accounted for\n",
    "(In terms of manual mappings for env_package.) But we can prioritize NMDC for now:\n",
    "\n",
    "- Soil 15,777\n",
    "- Sediment 7,147\n",
    "- Plant-associated 3,142\n",
    "\n",
    "Could some of these \"no environmental package\" mappings be losing important granularity?\n",
    "\n",
    "Map `None` and '' to \"no environmental package\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_package_overrides = {\n",
    "    \"built environment\": \"built\",\n",
    "    \"misc environment\": \"miscellaneous\",\n",
    "    \"missing\": \"no environmental package\",\n",
    "    \"unknown\": \"no environmental package\",\n",
    "    \"default\": \"no environmental package\",\n",
    "    \"unspecified\": \"no environmental package\",\n",
    "    \"not available\": \"no environmental package\",\n",
    "    \"not collected\": \"no environmental package\",\n",
    "    \"miscellaneous natural or artificial environment\": \"miscellaneous\",\n",
    "    \"not applicable\": \"no environmental package\",\n",
    "    \"soil-associated\": \"soil\",\n",
    "    \"soil associated\": \"soil\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_cnx = sqlite3.connect(biosample_sqlite_file)\n",
    "\n",
    "first_pass_ontologies.insert(0, target_onto_prefix.lower())\n",
    "first_pass_ontologies_str = \",\".join(first_pass_ontologies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine ID patterns for common ontologies, like `ENVO`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_pass_ontologies, including primary but not ncbitaxon\n",
    "# doesn't check for exisitence of DB files\n",
    "\n",
    "temp = first_pass_ontologies\n",
    "temp = [each_string.lower() for each_string in temp]\n",
    "temp.sort()\n",
    "temp = [each_string for each_string in temp if each_string != \"ncbitaxon\"]\n",
    "\n",
    "print(temp)\n",
    "\n",
    "first_pass_id_frames = []\n",
    "for one_ontology in temp:\n",
    "    print(one_ontology)\n",
    "    one_db_file = \"../../../scoped-mapping/semantic-sql/db/\" + one_ontology.lower() + \".db\"\n",
    "    print(one_db_file)\n",
    "    one_con = sqlite3.connect(one_db_file)\n",
    "\n",
    "    # FIXED? this wont include a term unless it's a class with a label\n",
    "    # add obsolete tags?\n",
    "    # may want to make a local-label only frame for later tasks?\n",
    "\n",
    "    q = \"\"\"\n",
    "select\n",
    "\tdistinct s1.stanza,\n",
    "\ts2.value\n",
    "from\n",
    "\tstatements s1\n",
    "left join statements s2 on\n",
    "\ts2.subject = s1.subject\n",
    "where\n",
    "\ts1.predicate = 'rdf:type'\n",
    "\tand s1.object = 'owl:Class'\n",
    "\tand s1.stanza = s1.subject\n",
    "\tand s2.predicate = 'rdfs:label'\"\"\"\n",
    "    [ids_labs_selected_ontolgies, query_duration] = scoped_mapping.timed_query(\n",
    "        q, one_con\n",
    "    )\n",
    "    print(query_duration)\n",
    "    ids_labs_selected_ontolgies[\"ontology\"] = one_ontology\n",
    "    first_pass_id_frames.append(ids_labs_selected_ontolgies)\n",
    "    one_con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_labs_selected_ontolgies = pd.concat(first_pass_id_frames)\n",
    "ids_labs_selected_ontolgies.to_sql(\n",
    "    \"ids_labs_selected_ontolgies\", biosample_cnx, if_exists=\"replace\", index=False\n",
    ")\n",
    "\n",
    "ids_labs_selected_ontolgies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_labs_selected_ontolgies = scoped_mapping.add_prefix_col(\n",
    "    ids_labs_selected_ontolgies, \"stanza\", \"prefix\"\n",
    ")\n",
    "ids_labs_selected_ontolgies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_patterns = scoped_mapping.get_multi_term_patterns(\n",
    "    ids_labs_selected_ontolgies, \"stanza\", \"prefix\"\n",
    ")\n",
    "\n",
    "id_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipf = pd.DataFrame(id_patterns.items(), columns=[\"ontology\", \"id_pattern\"])\n",
    "ipf.to_sql(\"id_patterns\", biosample_cnx, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # round trip\n",
    "# ipd = dict(zip(ipf.ontology, ipf.id_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreive `env_package` values from Biosample table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    env_package,\n",
    "    count(*) as count\n",
    "from\n",
    "    biosample b\n",
    "group by\n",
    "    env_package\n",
    "order by\n",
    "    count(*) desc\n",
    "\"\"\"\n",
    "[env_package_count, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "env_package_count.to_csv(\"env_package_count\")\n",
    "\n",
    "env_package_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply some normalization rules to the `env_package` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bumped splits from two to three. should genrealize.\n",
    "\n",
    "env_package_normalization = scoped_mapping.env_package_nomralizastion(\n",
    "    env_package_count, \"env_package\", id_patterns[target_onto_prefix]\n",
    ")\n",
    "\n",
    "\n",
    "# getting rid of redundant? 'string' column\n",
    "env_package_normalization = env_package_normalization[\n",
    "    [   \"env_package\",\n",
    "        \"count\",\n",
    "        \"lhs\",\n",
    "        \"rhs\",\n",
    "        \"extract\",\n",
    "        \"remaining_string\",\n",
    "        \"remaining_tidied\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "env_package_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_dictionary = scoped_mapping.get_package_dictionary(biosample_packages_file)\n",
    "package_dictionary.to_sql(\n",
    "    \"package_dictionary\", biosample_cnx, if_exists=\"replace\", index=False\n",
    ")\n",
    "package_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pick \"EnvPackage\"/\"eptidy\" from package dictionary as canonical, not \"EnvPackageDisplay\"/\"epdtidy\"\n",
    "\n",
    "\n",
    "But still want to support making XXX values from YYY canonical according to \"EnvPackageDisplay\"/\"epdtidy\", so make a mapping/override table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package_dictionary = scoped_mapping.make_tidy_col(\n",
    "    package_dictionary, \"EnvPackage\", \"eptidy\"\n",
    ")\n",
    "package_dictionary = scoped_mapping.make_tidy_col(\n",
    "    package_dictionary, \"EnvPackageDisplay\", \"epdtidy\"\n",
    ")\n",
    "\n",
    "# update in sqlite\n",
    "package_dictionary.to_sql(\n",
    "    \"package_dictionary\", biosample_cnx, if_exists=\"replace\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epd_to_ep = package_dictionary[[\"eptidy\", \"epdtidy\"]]\n",
    "# drop duplicates\n",
    "epd_to_ep = epd_to_ep.drop_duplicates()\n",
    "\n",
    "# drop blank eptidy rows\n",
    "ep_blank_flag = epd_to_ep[\"eptidy\"].eq(\"\")\n",
    "epd_to_ep = epd_to_ep.loc[~ep_blank_flag]\n",
    "\n",
    "# drop rows where eptidy and epdtidy are the same\n",
    "identical_flag = epd_to_ep[\"eptidy\"] == epd_to_ep[\"epdtidy\"]\n",
    "epd_to_ep = epd_to_ep.loc[~identical_flag]\n",
    "\n",
    "epd_to_ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and add to manualy asserted overrides above\n",
    "overrides_supplement = dict(zip(epd_to_ep[\"epdtidy\"], epd_to_ep[\"eptidy\"]))\n",
    "\n",
    "overrides_supplement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_package_overrides.update(overrides_supplement)\n",
    "\n",
    "env_package_overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_package_normalization = scoped_mapping.add_overrides(\n",
    "    env_package_normalization, \"remaining_tidied\", \"rt_override\", env_package_overrides\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm_frame = package_dictionary[[\"EnvPackage\", \"eptidy\"]]\n",
    "denorm_frame = denorm_frame.drop_duplicates()\n",
    "denorm_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_package_normalization = env_package_normalization.merge(\n",
    "    denorm_frame, how=\"left\", left_on=\"rt_override\", right_on=\"eptidy\"\n",
    ")\n",
    "\n",
    "env_package_normalization = env_package_normalization[\n",
    "    [\n",
    "        \"env_package\",\n",
    "        \"count\",\n",
    "        \"lhs\",\n",
    "        \"rhs\",\n",
    "        \"extract\",\n",
    "        \"remaining_string\",\n",
    "        \"remaining_tidied\",\n",
    "        \"rt_override\",\n",
    "        \"EnvPackage\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "non_canonical_flag = env_package_normalization[\"EnvPackage\"].isna()\n",
    "env_package_normalization[\"is_canonical\"] = True\n",
    "env_package_normalization.loc[non_canonical_flag, \"is_canonical\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- env_package = env_package annotation from NCBI Biosample file XXX\n",
    "- count = number of biosamples using that env_package annotation\n",
    "- lhs = checklist info\n",
    "- rhs = potential package info\n",
    "- extract = potential OBO ID from rhs column (currently harcoded and only looking for ENVO IDs)\n",
    "- remaining_string = rhs/string, with potential OBO IDs removed\n",
    "- remaining_tidied = remaining_string with case, whitespace and punctuation normailzastion\n",
    "- rt_override = some remaining_tidied values can be replaced according to env_package_overrides\n",
    "- EnvPackage = corresponding de-normalized value from package_dictionary\n",
    "- is_canonical = false when EnvPackage is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_package_normalization.to_sql(\n",
    "    \"env_package_normalization\", biosample_cnx, if_exists=\"replace\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_package_normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do the successful normalizations look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    env_package,\n",
    "    count,\n",
    "    lhs,\n",
    "    extract,\n",
    "    EnvPackage\n",
    "from\n",
    "    env_package_normalization\n",
    "where\n",
    "    is_canonical = 1\n",
    "\"\"\"\n",
    "[successful_normalizastions, query_duration] = scoped_mapping.timed_query(\n",
    "    q, biosample_cnx\n",
    ")\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "successful_normalizastions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are there any normalization failures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    env_package,\n",
    "    count,\n",
    "    lhs,\n",
    "    extract,\n",
    "    EnvPackage\n",
    "from\n",
    "    env_package_normalization\n",
    "where\n",
    "    is_canonical = 0\n",
    "\"\"\"\n",
    "[normalizastion_failures, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "normalizastion_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = biosample_cnx.cursor()\n",
    "statement = \"\"\"\n",
    "DROP TABLE if exists repaired_env_package ;\n",
    "\n",
    "CREATE TABLE repaired_env_package AS\n",
    "select\n",
    "\tb.id,\n",
    "\tepn.env_package as env_package_orig,\n",
    "\tepn.EnvPackage as env_package_rep\n",
    "from\n",
    "\tenv_package_normalization epn\n",
    "join biosample b on\n",
    "\tb.env_package = epn.env_package\n",
    "where\n",
    "\tis_canonical = 1\n",
    "\tand EnvPackage != '';\n",
    "\t\n",
    "select\n",
    "\tcount(*)\n",
    "from\n",
    "\trepaired_env_package rep\n",
    "\"\"\"\n",
    "\n",
    "cursor.executescript(statement)\n",
    "biosample_cnx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
